<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Perception | Cognitive Foundations</title>
  <meta name="description" content="Chapter 2 Perception | Cognitive Foundations is a free, open, collaboratively-authored textbook. It is an introduction to cognitive psychology written at the foundational level. This collaborative OER book project represents the work of dozens of authors and collaborators. The first edition brought multiple open texts together, edited into a single book with a consistent voice and formatting. For the second edition, a team of content experts reviewed and updated the materials." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Perception | Cognitive Foundations" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://pilegard.github.io/cogfoundations/images/cover.png" />
  <meta property="og:description" content="Chapter 2 Perception | Cognitive Foundations is a free, open, collaboratively-authored textbook. It is an introduction to cognitive psychology written at the foundational level. This collaborative OER book project represents the work of dozens of authors and collaborators. The first edition brought multiple open texts together, edited into a single book with a consistent voice and formatting. For the second edition, a team of content experts reviewed and updated the materials." />
  <meta name="github-repo" content="pilegard/cogfoundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Perception | Cognitive Foundations" />
  
  <meta name="twitter:description" content="Chapter 2 Perception | Cognitive Foundations is a free, open, collaboratively-authored textbook. It is an introduction to cognitive psychology written at the foundational level. This collaborative OER book project represents the work of dozens of authors and collaborators. The first edition brought multiple open texts together, edited into a single book with a consistent voice and formatting. For the second edition, a team of content experts reviewed and updated the materials." />
  <meta name="twitter:image" content="https://pilegard.github.io/cogfoundations/images/cover.png" />

<meta name="author" content="Edited by Celeste Pilegard" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="history-and-research-methods.html"/>
<link rel="next" href="attention.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ZM78LRWCWG"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-ZM78LRWCWG');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/logo.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-book"><i class="fa fa-check"></i>About the Book</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#adoption-and-contact-information"><i class="fa fa-check"></i>Adoption and Contact Information</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-history"><i class="fa fa-check"></i>Version History</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license-and-attributions"><i class="fa fa-check"></i>License and Attributions</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-1.-history-and-research-methods"><i class="fa fa-check"></i>Chapter 1. History and Research Methods</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-2.-perception"><i class="fa fa-check"></i>Chapter 2. Perception</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-3.-attention"><i class="fa fa-check"></i>Chapter 3. Attention</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-4.-working-memory"><i class="fa fa-check"></i>Chapter 4. Working Memory</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-5.-long-term-memory"><i class="fa fa-check"></i>Chapter 5. Long-Term Memory</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-6.-memory-in-context"><i class="fa fa-check"></i>Chapter 6. Memory in Context</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-7.-knowledge"><i class="fa fa-check"></i>Chapter 7. Knowledge</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-8.-language"><i class="fa fa-check"></i>Chapter 8. Language</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-9.-reasoning-and-decision-making"><i class="fa fa-check"></i>Chapter 9. Reasoning and Decision Making</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-10.-problem-solving"><i class="fa fa-check"></i>Chapter 10. Problem Solving</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html"><i class="fa fa-check"></i><b>1</b> History and Research Methods</a>
<ul>
<li class="chapter" data-level="1.1" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#rise-of-cognitive-psychology"><i class="fa fa-check"></i><b>1.1</b> Rise of Cognitive Psychology</a>
<ul>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#experimental-psychologys-foundations"><i class="fa fa-check"></i>Experimental Psychology’s Foundations</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#the-growth-of-psychology"><i class="fa fa-check"></i>The Growth of Psychology</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#cognitive-revolution"><i class="fa fa-check"></i>Cognitive Revolution</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#research-methods-in-psychology"><i class="fa fa-check"></i><b>1.2</b> Research Methods in Psychology</a>
<ul>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#experimental-research"><i class="fa fa-check"></i>Experimental Research</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#correlational-designs"><i class="fa fa-check"></i>Correlational Designs</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#qualitative-designs"><i class="fa fa-check"></i>Qualitative Designs</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#quasi-experimental-designs"><i class="fa fa-check"></i>Quasi-Experimental Designs</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#longitudinal-studies"><i class="fa fa-check"></i>Longitudinal Studies</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#tradeoffs-in-research"><i class="fa fa-check"></i>Tradeoffs in Research</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#glossary"><i class="fa fa-check"></i><b>1.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="perception.html"><a href="perception.html"><i class="fa fa-check"></i><b>2</b> Perception</a>
<ul>
<li class="chapter" data-level="2.1" data-path="perception.html"><a href="perception.html#sensation-and-perception"><i class="fa fa-check"></i><b>2.1</b> Sensation and Perception</a>
<ul>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#seeing"><i class="fa fa-check"></i>Seeing</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#the-sensing-eye-and-the-perceiving-visual-cortex"><i class="fa fa-check"></i>The Sensing Eye and the Perceiving Visual Cortex</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#perceiving-depth"><i class="fa fa-check"></i>Perceiving Depth</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#perceiving-form"><i class="fa fa-check"></i>Perceiving Form</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="perception.html"><a href="perception.html#perception-information-integration"><i class="fa fa-check"></i><b>2.2</b> Perception: Information Integration</a>
<ul>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#how-the-perceptual-system-interprets-the-environment"><i class="fa fa-check"></i>How the Perceptual System Interprets the Environment</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#illusions"><i class="fa fa-check"></i>Illusions</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#the-important-role-of-expectations-in-perception"><i class="fa fa-check"></i>The Important Role of Expectations in Perception</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="perception.html"><a href="perception.html#glossary-1"><i class="fa fa-check"></i><b>2.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="attention.html"><a href="attention.html"><i class="fa fa-check"></i><b>3</b> Attention</a>
<ul>
<li class="chapter" data-level="3.1" data-path="attention.html"><a href="attention.html#what-is-attention"><i class="fa fa-check"></i><b>3.1</b> What is Attention?</a></li>
<li class="chapter" data-level="3.2" data-path="attention.html"><a href="attention.html#selective-attention"><i class="fa fa-check"></i><b>3.2</b> Selective Attention</a>
<ul>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#the-cocktail-party"><i class="fa fa-check"></i>The Cocktail Party</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#dichotic-listening-studies"><i class="fa fa-check"></i>Dichotic Listening Studies</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#models-of-selective-attention"><i class="fa fa-check"></i>Models of Selective Attention</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#selective-attention-beyond-the-auditory-domain"><i class="fa fa-check"></i>Selective Attention Beyond the Auditory Domain</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="attention.html"><a href="attention.html#controlling-attention"><i class="fa fa-check"></i><b>3.3</b> Controlling Attention</a>
<ul>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#sustaining-attention"><i class="fa fa-check"></i>Sustaining Attention</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#switching-attention"><i class="fa fa-check"></i>Switching Attention</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#multitasking"><i class="fa fa-check"></i>Multitasking</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#distracted-driving"><i class="fa fa-check"></i>Distracted Driving</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="attention.html"><a href="attention.html#glossary-2"><i class="fa fa-check"></i><b>3.4</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="working-memory-chapter.html"><a href="working-memory-chapter.html"><i class="fa fa-check"></i><b>4</b> Short-term and Working Memory</a>
<ul>
<li class="chapter" data-level="4.1" data-path="working-memory-chapter.html"><a href="working-memory-chapter.html#short-term-memory"><i class="fa fa-check"></i><b>4.1</b> Short-Term Memory</a>
<ul>
<li class="chapter" data-level="" data-path="working-memory-chapter.html"><a href="working-memory-chapter.html#from-the-modal-model-to-baddeleys-working-memory-model"><i class="fa fa-check"></i>From the Modal Model to Baddeley’s Working Memory Model</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="working-memory-chapter.html"><a href="working-memory-chapter.html#working-memory"><i class="fa fa-check"></i><b>4.2</b> Working Memory</a>
<ul>
<li class="chapter" data-level="" data-path="working-memory-chapter.html"><a href="working-memory-chapter.html#the-episodic-buffer"><i class="fa fa-check"></i>The episodic buffer</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="working-memory-chapter.html"><a href="working-memory-chapter.html#glossary-3"><i class="fa fa-check"></i><b>4.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html"><i class="fa fa-check"></i><b>5</b> Long-term Memory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#working-memory-vs.-long-term-memory"><i class="fa fa-check"></i><b>5.1</b> Working Memory Vs. Long-Term Memory</a>
<ul>
<li class="chapter" data-level="" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#the-serial-position-curve"><i class="fa fa-check"></i>The Serial Position Curve</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#structure"><i class="fa fa-check"></i><b>5.2</b> Structure</a>
<ul>
<li class="chapter" data-level="" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#explicit-memory"><i class="fa fa-check"></i>Explicit Memory</a></li>
<li class="chapter" data-level="" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#implicit-memory"><i class="fa fa-check"></i>Implicit Memory</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#encoding-retrieval-and-consolidation"><i class="fa fa-check"></i><b>5.3</b> Encoding, Retrieval, and Consolidation</a>
<ul>
<li class="chapter" data-level="" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#encoding"><i class="fa fa-check"></i>Encoding</a></li>
<li class="chapter" data-level="" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#retrieval"><i class="fa fa-check"></i>Retrieval</a></li>
<li class="chapter" data-level="" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#consolidation"><i class="fa fa-check"></i>Consolidation</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="long-term-memory-chapter.html"><a href="long-term-memory-chapter.html#glossary-4"><i class="fa fa-check"></i><b>5.4</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="memory-in-context.html"><a href="memory-in-context.html"><i class="fa fa-check"></i><b>6</b> Memory in Context</a>
<ul>
<li class="chapter" data-level="6.1" data-path="memory-in-context.html"><a href="memory-in-context.html#kinds-of-memory-biases"><i class="fa fa-check"></i><b>6.1</b> Kinds of Memory Biases</a>
<ul>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#schematic-processing-distortions-based-on-expectations"><i class="fa fa-check"></i>Schematic Processing: Distortions Based on Expectations</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#source-monitoring"><i class="fa fa-check"></i>Source Monitoring</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#memory-contamination"><i class="fa fa-check"></i>Memory Contamination</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="memory-in-context.html"><a href="memory-in-context.html#memory-in-the-eyewitness-domain"><i class="fa fa-check"></i><b>6.2</b> Memory in the Eyewitness Domain</a></li>
<li class="chapter" data-level="6.3" data-path="memory-in-context.html"><a href="memory-in-context.html#forgetting"><i class="fa fa-check"></i><b>6.3</b> Forgetting</a>
<ul>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#encoding-failure"><i class="fa fa-check"></i>Encoding Failure</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#interference"><i class="fa fa-check"></i>Interference</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#cue-overload-principle"><i class="fa fa-check"></i>Cue-Overload Principle</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="memory-in-context.html"><a href="memory-in-context.html#glossary-5"><i class="fa fa-check"></i><b>6.4</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="knowledge.html"><a href="knowledge.html"><i class="fa fa-check"></i><b>7</b> Knowledge</a>
<ul>
<li class="chapter" data-level="7.1" data-path="knowledge.html"><a href="knowledge.html#nature-of-categories"><i class="fa fa-check"></i><b>7.1</b> Nature of Categories</a>
<ul>
<li class="chapter" data-level="" data-path="knowledge.html"><a href="knowledge.html#typicality"><i class="fa fa-check"></i>Typicality</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="knowledge.html"><a href="knowledge.html#theories-of-concept-representation"><i class="fa fa-check"></i><b>7.2</b> Theories of Concept Representation</a></li>
<li class="chapter" data-level="7.3" data-path="knowledge.html"><a href="knowledge.html#organization-of-concepts"><i class="fa fa-check"></i><b>7.3</b> Organization of Concepts</a>
<ul>
<li class="chapter" data-level="" data-path="knowledge.html"><a href="knowledge.html#semantic-networks"><i class="fa fa-check"></i>Semantic Networks</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="knowledge.html"><a href="knowledge.html#mental-models"><i class="fa fa-check"></i><b>7.4</b> Mental Models</a>
<ul>
<li class="chapter" data-level="" data-path="knowledge.html"><a href="knowledge.html#a-theory-of-mind"><i class="fa fa-check"></i>A Theory of Mind</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="knowledge.html"><a href="knowledge.html#glossary-6"><i class="fa fa-check"></i><b>7.5</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="language.html"><a href="language.html"><i class="fa fa-check"></i><b>8</b> Language</a>
<ul>
<li class="chapter" data-level="8.1" data-path="language.html"><a href="language.html#what-is-language"><i class="fa fa-check"></i><b>8.1</b> What is Language?</a>
<ul>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#linguistic-diversity"><i class="fa fa-check"></i>Linguistic Diversity</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#the-components-of-language"><i class="fa fa-check"></i>The Components of Language</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="language.html"><a href="language.html#mechanisms-of-language"><i class="fa fa-check"></i><b>8.2</b> Mechanisms of Language</a>
<ul>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#language-processing"><i class="fa fa-check"></i>Language Processing</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#language-production"><i class="fa fa-check"></i>Language Production</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="language.html"><a href="language.html#language-acquisition"><i class="fa fa-check"></i><b>8.3</b> Language Acquisition</a>
<ul>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#language-environment-and-cognitive-development"><i class="fa fa-check"></i>Language Environment and Cognitive Development</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#bilingualism"><i class="fa fa-check"></i>Bilingualism</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#adult-language-acquisition"><i class="fa fa-check"></i>Adult Language Acquisition</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="language.html"><a href="language.html#language-and-thought"><i class="fa fa-check"></i><b>8.4</b> Language and Thought</a></li>
<li class="chapter" data-level="8.5" data-path="language.html"><a href="language.html#glossary-7"><i class="fa fa-check"></i><b>8.5</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html"><i class="fa fa-check"></i><b>9</b> Reasoning and Decision Making</a>
<ul>
<li class="chapter" data-level="9.1" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#reasoning"><i class="fa fa-check"></i><b>9.1</b> Reasoning</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#deductive-reasoning"><i class="fa fa-check"></i><b>9.1.1</b> Deductive reasoning</a></li>
<li class="chapter" data-level="9.1.2" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#inductive-reasoning"><i class="fa fa-check"></i><b>9.1.2</b> Inductive reasoning</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#decision-making"><i class="fa fa-check"></i><b>9.2</b> Decision making</a>
<ul>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#theories-of-decision-making"><i class="fa fa-check"></i>Theories of Decision Making</a></li>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#constructed-preferences"><i class="fa fa-check"></i>Constructed Preferences</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="problem-solving.html"><a href="problem-solving.html"><i class="fa fa-check"></i><b>10</b> Problem Solving</a>
<ul>
<li class="chapter" data-level="10.1" data-path="problem-solving.html"><a href="problem-solving.html#what-is-a-problem"><i class="fa fa-check"></i><b>10.1</b> What is a problem?</a>
<ul>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#well-defined-problems"><i class="fa fa-check"></i>Well-defined Problems</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#ill-defined-problems"><i class="fa fa-check"></i>Ill-defined Problems</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="problem-solving.html"><a href="problem-solving.html#restructuring-the-gestalt-approach"><i class="fa fa-check"></i><b>10.2</b> Restructuring: The Gestalt Approach</a>
<ul>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#how-is-a-problem-represented-in-the-mind"><i class="fa fa-check"></i>How is a problem represented in the mind?</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#insight"><i class="fa fa-check"></i>Insight</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#fixation"><i class="fa fa-check"></i>Fixation</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="problem-solving.html"><a href="problem-solving.html#solving-problems-by-analogy"><i class="fa fa-check"></i><b>10.3</b> Solving Problems by Analogy</a></li>
<li class="chapter" data-level="10.4" data-path="problem-solving.html"><a href="problem-solving.html#creativity"><i class="fa fa-check"></i><b>10.4</b> Creativity</a>
<ul>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#defining-creativity"><i class="fa fa-check"></i>Defining Creativity</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#creative-thinking"><i class="fa fa-check"></i>Creative Thinking</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="problem-solving.html"><a href="problem-solving.html#how-do-experts-solve-problems"><i class="fa fa-check"></i><b>10.5</b> How do Experts Solve Problems?</a>
<ul>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#knowledge-1"><i class="fa fa-check"></i>Knowledge</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#organization"><i class="fa fa-check"></i>Organization</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#analysis"><i class="fa fa-check"></i>Analysis</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#the-curse-of-expertise"><i class="fa fa-check"></i>The Curse of Expertise</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="problem-solving.html"><a href="problem-solving.html#glossary-8"><i class="fa fa-check"></i><b>10.6</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cognitive Foundations</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="perception" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Perception<a href="perception.html#perception" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><img src="images/ch2/intro.jpeg" width="100%" style="display: block; margin: auto;" /></p>
<p>Right now, as you read these words, your brain is performing an extraordinary feat. Light waves bouncing off this page are hitting your eyes, but somehow you’re not seeing meaningless patterns of black marks; you’re seeing letters, words, and ideas. Your perceptual system takes fragmented, upside-down, constantly shifting sensory information and transforms it into a coherent, meaningful experience of the world. Perception isn’t just passive reception of information; it’s an active process of interpretation and construction.</p>
<p>Studying perception reveals something profound about human experience: the world you perceive isn’t simply “out there” – it’s actively constructed by your brain.</p>
<div id="learning-objectives-1" class="section level5 unnumbered hasAnchor learningobjectives">
<h5>LEARNING OBJECTIVES<a href="perception.html#learning-objectives-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li>Review and summarize the capacities and limitations of human sensation.</li>
<li>Identify the key structures of the eye and the role they play in vision.</li>
<li>Describe how sensation and perception work together through sensory interaction, selective attention, sensory adaptation, and perceptual constancy.</li>
<li>Give examples of how our expectations may influence our perception, resulting in illusions and potentially inaccurate judgments.</li>
</ol>
</div>
<div id="sensation-and-perception" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Sensation and Perception<a href="perception.html#sensation-and-perception" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The ability to detect and interpret the events that are occurring around us allows us to respond to these stimuli appropriately <span class="citation">(<a href="#ref-Gibson2000">Gibson et al., 2000</a>)</span>. In most cases the system is successful, but it is not perfect. In this chapter we will discuss the strengths and limitations of these capacities, focusing on both <a href="perception.html#sensation">sensation</a> — the stimulation of sensory receptor cells, which is converted to neural impulses — and <a href="perception.html#perception">perception</a> — our experience as a result of that stimulation. Sensation and perception work seamlessly together to allow us to experience the world through our eyes, ears, nose, tongue, and skin, but also to combine what we are currently learning from the environment with what we already know about it (prior knowledge) in order to make judgments and to choose appropriate behaviors.</p>
<p>Humans possess powerful sensory capacities that allow us to sense the kaleidoscope of sights, sounds, smells, and tastes that surround us. Our eyes detect light energy and our ears pick up sound waves. Our skin senses touch, pressure, hot, and cold. Our tongues react to the molecules of the foods we eat, and our noses detect scents in the air. The human sensory and perceptual systems are wired for accuracy, and people are exceedingly good at making use of the wide variety of information available to them <span class="citation">(<a href="#ref-Stoffregen2001">Stoffregen &amp; Bardy, 2001</a>)</span>.</p>
<p>In many ways, our senses are quite remarkable. The human eye can detect the equivalent of a single candle flame burning 30 miles away and can distinguish among more than 300,000 different colors. The human ear can detect sounds as low as 20 hertz (vibrations per second) and as high as 20,000 hertz, and it can hear the tick of a clock about 20 feet away in a quiet room. We can taste a teaspoon of sugar dissolved in two gallons of water, and we are able to smell one drop of perfume diffused in a three-room apartment. We can feel the wing of a bee on our cheek dropped from one centimeter above <span class="citation">(<a href="#ref-Galanter1962">Galanter, 1962</a>)</span>.</p>
<div id="seeing" class="section level3 unnumbered hasAnchor">
<h3>Seeing<a href="perception.html#seeing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Whereas other animals rely primarily on hearing, smell, or touch to understand the world around them, humans rely in large part on vision. Thus, vision will be the primary sense we focus on in this chapter. A large part of our cerebral cortex is devoted to seeing, and we have substantial visual skills. Seeing begins when light falls on the eyes, initiating the process of <a href="perception.html#transduction">transduction</a>, the conversion of light detected by receptor cells to electrical impulses that are transported to the brain. Once this visual information reaches the visual cortex, it is processed by a variety of neurons that detect colors, shapes, and motion, and that create meaningful perceptions out of the incoming stimuli. The brain does this in part by combining incoming information with our expectations and prior knowledge about the world.</p>
</div>
<div id="the-sensing-eye-and-the-perceiving-visual-cortex" class="section level3 unnumbered hasAnchor">
<h3>The Sensing Eye and the Perceiving Visual Cortex<a href="perception.html#the-sensing-eye-and-the-perceiving-visual-cortex" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As you can see in Figure <a href="perception.html#fig:anatomy">2.1</a>, light enters the eye through the <a href="perception.html#cornea">cornea</a>, a clear covering that protects the eye and begins to focus the incoming light. The light then passes through the <a href="perception.html#pupil">pupil</a>, a small opening in the center of the eye. The pupil is surrounded by the <a href="perception.html#iris">iris</a>, the colored part of the eye that controls the size of the pupil by constricting or dilating in response to light intensity. When we enter a dark movie theater on a sunny day, for instance, muscles in the iris open the pupil and allow more light to enter. Complete adaptation to the dark may take up to 20 minutes.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:anatomy"></span>
<img src="images/ch2/fig1.jpg" alt="Anatomy of the Human Eye. Behind the pupil is the lens, a structure that focuses the incoming light on the retina, the layer of tissue at the back of the eye that contains photoreceptor cells. Rays from the top of the image strike the bottom of the retina and vice versa, and rays from the left side of the image strike the right part of the retina and vice versa, causing the image on the retina to be upside down." width="60%" />
<p class="caption">
Figure 2.1: Anatomy of the Human Eye. Behind the pupil is the lens, a structure that focuses the incoming light on the retina, the layer of tissue at the back of the eye that contains photoreceptor cells. Rays from the top of the image strike the bottom of the retina and vice versa, and rays from the left side of the image strike the right part of the retina and vice versa, causing the image on the retina to be upside down.
</p>
</div>
<p>Behind the pupil is the <a href="perception.html#lens">lens</a>, a structure that focuses the incoming light on the <a href="perception.html#retina">retina</a>, the layer of tissue at the back of the eye that contains photoreceptor cells. Rays from the top of the image strike the bottom of the retina and vice versa, and rays from the left side of the image strike the right part of the retina and vice versa, causing the image on the retina to be upside down.</p>
<p>The retina contains layers of neurons specialized to respond to light. As light falls on the retina, it first activates receptor cells known as <em>rods</em> and <em>cones</em>. The activation of these cells then spreads to the <em>bipolar cells</em> and then to the <em>ganglion cells</em>, which gather together and converge, like the strands of a rope, forming the <em>optic nerve</em>. The <a href="perception.html#optic-nerve">optic nerve</a> is a collection of millions of ganglion neurons that sends vast amounts of visual information, via a structure in the middle of the brain called the thalamus, to the visual cortex, which starts at the back of the brain (thus validating to the phrase, “I have eyes in the back of my head”). Because the retina and the optic nerve are active processors and analyzers of visual information, it is appropriate to think of these structures as an extension of the brain itself.</p>
<p><a href="perception.html#rods">Rods</a> are sensory receptor neurons that specialize in detecting black, white, and gray colors. There are about 120 million rods in each eye. The rods do not provide a lot of detail about the images we see, but because they are highly sensitive to shorter-waved (darker) and weak light, they help us see in dim light — for instance, at night. Because the rods are located primarily around the edges of the retina, they are particularly active in peripheral vision (when you need to see something at night, try looking slightly to the side of what you want to see in order to activate more of your highly sensitive rod receptors). <a href="perception.html#cones">Cones</a> are sensory receptor neurons that are specialized in detecting fine detail and colors. The five million or so cones in each eye enable us to see in color, but they operate best in bright light. The cones are located primarily in and around the <a href="perception.html#fovea">fovea</a>, which is the central point of the retina.</p>
<p>To demonstrate the difference between rods and cones in attention to detail, choose a word in this text and focus on it. Do you notice that the words a few inches to the side seem more blurred? This is because the word you are focusing on strikes the detail-oriented cones, while the words surrounding it strike the less-detail-oriented rods, which are located on the periphery.</p>
<p>Margaret <span class="citation">Livingstone (<a href="#ref-livingstone2000warm">2000</a>)</span> (Figure <a href="perception.html#fig:monalisa">2.2</a>) found an interesting effect that demonstrates the different processing capacities of the eye’s rods and cones — namely, that the Mona Lisa’s smile, which is widely referred to as “elusive,” is perceived differently depending on how one looks at the painting. Because Leonardo da Vinci painted the smile in low-detail brush strokes, the smile is actually better perceived by the rods in our peripheral vision than by the cones. Livingstone found that people rated the Mona Lisa as more cheerful when they were instructed to focus on her eyes than they did when they were asked to look directly at her mouth. As Livingstone put it, “She smiles until you look at her mouth, and then it fades, like a dim star that disappears when you look directly at it.”</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:monalisa"></span>
<img src="images/ch2/fig2.jpg" alt="Mona Lisa's smile." width="30%" />
<p class="caption">
Figure 2.2: Mona Lisa’s smile.
</p>
</div>
<p>The brain’s visual cortex is made up of specialized neurons that turn the sensations they receive from the optic nerve into meaningful representations of the world. Because there are no photoreceptor cells at the place where the optic nerve leaves the retina, a hole or <a href="perception.html#blind-spot">blind spot</a> in our vision is created (see Figure <a href="perception.html#fig:blindspot">2.3</a>). When both of our eyes are open, we don’t experience a “hole” in our awareness because our eyes are constantly moving, and one eye makes up for what the other eye misses. The visual system is also designed to deal with this problem if only one eye is open — the visual cortex simply fills in the small hole in our vision with similar patterns from the surrounding areas, and we never notice the difference. The visual system’s ability to cope with the blind spot is another example of how sensation and perception work together to create meaningful experience.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:blindspot"></span>
<img src="images/ch2/fig3.jpg" alt="Blind Spot Demonstration. You can get an idea of the extent of your blind spot (the place where the optic nerve leaves the retina) by trying this: close your left eye and stare with your right eye at the cross in the diagram. You should be able to see the elephant image to the right (don’t look at it, just notice that it is there). If you can’t see the elephant, move closer or farther away until you can. Now slowly move so that you are closer to the image while you keep looking at the cross. At one distance (around a foot or so depending on your zoom), the elephant will completely disappear from view because its image has fallen on the blind spot." width="60%" />
<p class="caption">
Figure 2.3: Blind Spot Demonstration. You can get an idea of the extent of your blind spot (the place where the optic nerve leaves the retina) by trying this: close your left eye and stare with your right eye at the cross in the diagram. You should be able to see the elephant image to the right (don’t look at it, just notice that it is there). If you can’t see the elephant, move closer or farther away until you can. Now slowly move so that you are closer to the image while you keep looking at the cross. At one distance (around a foot or so depending on your zoom), the elephant will completely disappear from view because its image has fallen on the blind spot.
</p>
</div>
</div>
<div id="perceiving-depth" class="section level3 unnumbered hasAnchor">
<h3>Perceiving Depth<a href="perception.html#perceiving-depth" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><a href="perception.html#depth-perception">Depth perception</a> is the ability to perceive three-dimensional space and to accurately judge distance. Without depth perception, we would be unable to drive a car, thread a needle, or simply navigate our way around the supermarket <span class="citation">(<a href="#ref-Howard2001">Howard, 2002</a>)</span>.</p>
<p>Depth perception is the result of our use of <a href="perception.html#depth-cues">depth cues</a>, messages from our bodies and the external environment that supply us with information about space and distance. <a href="perception.html#binocular-depth-cues">Binocular depth cues</a> are depth cues that are created by retinal image disparity — that is, the space between our eyes — and which thus require the coordination of both eyes. One outcome of retinal disparity is that the images projected on each eye are slightly different from each other. The visual cortex automatically merges the two images into one, enabling us to perceive depth. Three-dimensional movies make use of retinal disparity by using 3-D glasses that the viewer wears to create a different image on each eye. The perceptual system quickly, easily, and unconsciously turns the disparity into 3-D.</p>
<p>An important binocular depth cue is <a href="perception.html#convergence">convergence</a>, the inward turning of our eyes that is required to focus on objects that are less than about 50 feet away from us. The visual cortex uses the size of the convergence angle between the eyes to judge the object’s distance. You will be able to feel your eyes converging if you slowly bring a finger closer to your nose while continuing to focus on it. When you close one eye, you no longer feel the tension — convergence is a binocular depth cue that requires both eyes to work.</p>
<p>Although the best cues to depth occur when both eyes work together, we are able to see depth even with one eye closed. <a href="perception.html#monocular-depth-cues">Monocular depth cues</a> are depth cues that help us perceive depth using only one eye <span class="citation">(<a href="#ref-Sekuler2006">Sekuler &amp; Blake, 2006</a>)</span>. Some of the most important cues are summarized in Table <a href="perception.html#tab:monocular">2.1</a>.</p>
<table>
<caption><span id="tab:monocular">Table 2.1: </span> Monocular Depth Cues That Help Us Judge Depth at a Distance.</caption>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Description</th>
<th>Example</th>
<th>Image</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Position</td>
<td>We tend to see objects higher up in our field of vision as farther away.</td>
<td>The fence posts at right appear farther away not only because they become smaller but also because they appear higher up in the picture.</td>
<td><img src="images/ch2/depth1.jpg" /></td>
</tr>
<tr class="even">
<td>Relative size</td>
<td>Assuming that the objects in a scene are the same size, smaller objects are perceived as father away.</td>
<td>at right, the cars in the distance appear smaller than those nearer to us.</td>
<td><img src="images/ch2/depth2.jpg" /></td>
</tr>
<tr class="odd">
<td>Linear perspective</td>
<td>Parallel lines appear to converge at a distance.</td>
<td>We know that the tracks at right are parallel. When they appear closer together, we determine they are farther away.</td>
<td><img src="images/ch2/depth3.jpg" /></td>
</tr>
<tr class="even">
<td>Light and shadow</td>
<td>The eye receives more reflected light from objects that are closer to us. Normally, light comes from above, so darker images are in shadow.</td>
<td>We see the images at right as extending and indented according to their shadowing. If we invert the picture, the images will reverse.</td>
<td><img src="images/ch2/depth4.jpg" /></td>
</tr>
<tr class="odd">
<td>Interposition</td>
<td>When one object overlaps another object, we view it as closer.</td>
<td>At right, because the blue star covers the pink bar, it is seen as closer than the yellow moon.</td>
<td><img src="images/ch2/depth5.jpg" /></td>
</tr>
<tr class="even">
<td>Aerial perspective</td>
<td>Objects that appear hazy, or that are covered with smog or dust, appear farther away.</td>
<td>The artist who pained the picture on the right used aerial perspective to make the clouds more hazy and this appear farther away.</td>
<td><img src="images/ch2/depth6.jpg" /></td>
</tr>
</tbody>
</table>
</div>
<div id="perceiving-form" class="section level3 unnumbered hasAnchor">
<h3>Perceiving Form<a href="perception.html#perceiving-form" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the important functions of the visual system is the perception of form. German psychologists in the 1930s and 1940s, including Max Wertheimer (1880-1943), Kurt Koffka (1886-1941), and Wolfgang Köhler (1887-1967), argued that we create forms out of their component sensations based on the idea of the <em><a href="perception.html#gestalt">gestalt</a></em>, a meaningfully organized whole. The idea of the gestalt is that the “whole is more than the sum of its parts.” Some examples of how gestalt principles lead us to see more than what is actually there are summarized in Table <a href="perception.html#tab:gestalt">2.2</a>.</p>
<table>
<caption><span id="tab:gestalt">Table 2.2: </span> Summary of Gestalt Principles of Form Perception</caption>
<colgroup>
<col width="16%" />
<col width="25%" />
<col width="38%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Principle</th>
<th align="left">Description</th>
<th align="left">Example</th>
<th align="center">Image</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Figure and ground</td>
<td align="left">We structure input so that we always see a figure (image) against a ground (background).</td>
<td align="left">At right, you may see a vase or you may see two faces, but in either case, you will organize the image as a figure against a ground.</td>
<td align="center"><img src="images/ch2/gestalt1.jpg" /></td>
</tr>
<tr class="even">
<td align="left">Similarity</td>
<td align="left">Stimuli that are similar to each other tend to be grouped together.</td>
<td align="left">You are more likely to see three similar columns among the XYX characters at right than you are to see four rows.</td>
<td align="center"><img src="images/ch2/gestalt2.jpg" /></td>
</tr>
<tr class="odd">
<td align="left">Proximity</td>
<td align="left">We tend to group nearby figures together.</td>
<td align="left">Do you see four or eight images at right? Principles of proximity suggest that you might see only four.</td>
<td align="center"><img src="images/ch2/gestalt3.jpg" /></td>
</tr>
<tr class="even">
<td align="left">Continuity</td>
<td align="left">We tend to perceive stimuli in smooth, continuous ways rather than in more discontinuous ways.</td>
<td align="left">At right, most people see a line of dots that moves from the lower left to the upper right, rather than a line that moves from the left and then suddenly turns down. The principle of continuity leads us to see most lines as following the smoothest possible path.</td>
<td align="center"><img src="images/ch2/gestalt4.jpg" /></td>
</tr>
<tr class="odd">
<td align="left">Closure</td>
<td align="left">We tend to fill in gaps in an incomplete image to create a complete, whole object.</td>
<td align="left">Closure leads us to see a single spherical object at right rather than a set of unrelated cones.</td>
<td align="center"><img src="images/ch2/gestalt5.jpg" /></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="perception-information-integration" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Perception: Information Integration<a href="perception.html#perception-information-integration" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The eyes, ears, nose, tongue, and skin sense the world around us, and in some cases perform preliminary information processing on the incoming data. But by and large, what we end up “seeing” or experiencing is a result of our brain’s interpretation of the sensory information coming in, rather than a direct read out of that information. When we look out the window at a view of the countryside, or when we look at the face of a good friend, we don’t just see a jumble of colors and shapes — we see, instead, an image of a countryside or an image of a friend <span class="citation">(<a href="#ref-Goodale2006">Goodale &amp; Milner, 2006</a>)</span>. How our brain interprets and integrates sensory information in a way that leads to our everyday experience largely depends on attention, working memory, and other cognitive processes that will be discussed in future chapters of this book.</p>
<div id="how-the-perceptual-system-interprets-the-environment" class="section level3 unnumbered hasAnchor">
<h3>How the Perceptual System Interprets the Environment<a href="perception.html#how-the-perceptual-system-interprets-the-environment" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This process of understanding involves the automatic operation of a variety of essential perceptual processes. One of these is <a href="perception.html#sensory-interaction">sensory interaction</a> — the working together of different senses to create experience. For example, sensory interaction is involved when taste, smell, and texture combine to create the flavor we experience in food. It is also involved when we enjoy a movie because of the way the images and the music work together.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mcgurk"></span>
<img src="images/ch2/QR.png" alt="Watch The McGurk Effect [YouTube]: http://www.youtube.com/watch?v=jtsfidRq2tw " width="25%" />
<p class="caption">
Figure 2.4: Watch The McGurk Effect [YouTube]: <a href="http://www.youtube.com/watch?v=jtsfidRq2tw" class="uri">http://www.youtube.com/watch?v=jtsfidRq2tw</a>
</p>
</div>
<p>Although you might think that we understand speech only through our sense of hearing, it turns out that the visual aspect of speech is also important. One example of sensory interaction is shown in the <a href="perception.html#mcgurk-effect">McGurk effect</a> — an error in perception that occurs when we misperceive sounds because the audio and visual parts of the speech are mismatched. You can witness the effect yourself by viewing the video in Figure <a href="perception.html#fig:mcgurk">2.4</a>.</p>
<p>Other examples of sensory interaction include the experience of nausea that can occur when the sensory information being received from the eyes and the body does not match information from the vestibular system <span class="citation">(<a href="#ref-Flanagan2004">Flanagan et al., 2004</a>)</span> and <a href="perception.html#synesthesia">synesthesia</a> — an experience in which one sensation (e.g., seeing a number) creates experiences in another (e.g., hearing a sound). Most people do not experience synesthesia, but those who do link their perceptions in unusual ways, for instance, by experiencing color when they taste a particular food or by hearing sounds when they see certain objects <span class="citation">(<a href="#ref-Ramachandran2005">Ramachandran et al., 2005</a>)</span>.</p>
<p>A more recent example of sensory interaction illustrates how sounds can directly shape our visual perception <span class="citation">(<a href="#ref-Williams2022">Williams et al., 2022</a>)</span>. Researchers showed people noisy images (e.g., a blurry image of a plane/bird) paired with naturalisitic sounds. Perception – whether they saw it as a plane or bird – was shaped by the sound that the image was paired with. If the image was paired with the sounds of a bird, people were more likely to see the image as a bird instead of a plane. This research shows that our perceptual experience of one sense (e.g., vision) is shaped by other senses (e.g., hearing).</p>
<p>A second fundamental process of perception is <a href="perception.html#sensory-adaptation">sensory adaptation</a> — a decreased sensitivity to a stimulus after prolonged and constant exposure. When you step into a swimming pool, the water initially feels cold, but after a while you stop noticing it. After prolonged exposure to the same stimulus, our sensitivity toward it diminishes and we no longer perceive it. The ability to adapt to the things that don’t change around us is essential to our survival, as it leaves our sensory receptors free to detect the important and informative changes in our environment and to respond accordingly. We ignore the sounds that our car makes every day, which leaves us free to pay attention to the sounds that are different from normal, and thus likely to need our attention. Our sensory receptors are alert to novelty and are fatigued after constant exposure to the same stimulus.</p>
<p>If sensory adaptation occurs with all senses, why doesn’t an image fade away after we stare at it for a period of time? The answer is that, although we are not aware of it, our eyes are constantly flitting from one angle to the next, making thousands of tiny movements (called <a href="perception.html#saccades">saccades</a>) every minute. This constant eye movement guarantees that the image we are viewing always falls on fresh receptor cells. What would happen if we could stop the movement of our eyes? Psychologists have devised a way of testing the sensory adaptation of the eye by attaching an instrument that ensures a constant image is maintained on the eye’s inner surface. Participants are fitted with a contact lens that has a miniature slide projector attached to it. Because the projector follows the exact movements of the eye, the same image is always projected, stimulating the same spot, on the retina. Within a few seconds, interesting things begin to happen. The image will begin to vanish, then reappear, only to disappear again, either in pieces or as a whole. Even the eye experiences sensory adaptation <span class="citation">(<a href="#ref-Yarbus1967">Yarbus, 1967</a>)</span>.</p>
<p>One of the major problems in perception is to ensure that we always perceive the same object in the same way, even when the sensations it creates on our receptors change dramatically. The ability to perceive a stimulus as constant despite changes in sensation is known as <a href="perception.html#perceptual-constancy">perceptual constancy</a>. Consider our image of a door as it swings. When it is closed, we see it as rectangular, but when it is open, we see only its edge and it appears as a line. But we never perceive the door as changing shape as it swings — perceptual mechanisms take care of the problem for us by allowing us to see a constant shape.</p>
<p>The visual system also corrects for color constancy. Imagine that you are wearing blue jeans and a bright white T-shirt. When you are outdoors, both colors will be at their brightest, but you will still perceive the white T-shirt as bright and the blue jeans as darker. When you go indoors, the light shining on the clothes will be significantly dimmer, but you will still perceive the T-shirt as bright. This is because we put colors in context and see that, compared with its surroundings, the white T-shirt reflects the most light <span class="citation">(<a href="#ref-McCann1992">McCann, 1992</a>)</span>. In the same way, a green leaf on a cloudy day may reflect the same wavelength of light as a brown tree branch does on a sunny day. Nevertheless, we still perceive the leaf as green and the branch as brown.</p>
<div id="why-are-computers-still-so-bad-at-perception" class="section level5 unnumbered hasAnchor fyi">
<h5>Why are computers still so bad at perception?<a href="perception.html#why-are-computers-still-so-bad-at-perception" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><a href="perception.html#computer-vision">Computer vision</a> refers to machines or algorithms that are built to mimic the human sensation and perception system. As we’ve learned, perception does not work like a camera, where we experience exactly what comes in through our senses. Instead, what we perceive is influenced by many factors, such as other sensory input, prior experiences, and expectations. Programming all of these components into a computer is difficult, and one reason why computer vision isn’t as good as we might expect it to be.</p>
<p>Another complication is that there are still significant gaps in our understanding of the human perceptual system. For instance, consider this: if perception is an integrative process that takes time, whatever we see now is no longer what is in front of us. Yet, humans can do amazing time-sensitive feats like hitting a 90-mph fastball in a baseball game. It appears then that a fundamental function of visual perception is not just to know what is happening around you now, but actually to make an accurate inference about what you are about to see next <span class="citation">(<a href="#ref-Enns2008">Enns &amp; Lleras, 2008</a>)</span>, so that you can keep up with the world. Understanding how this future-oriented, predictive function of perception is achieved in the brain is a largely unsolved challenge, and just another piece of the puzzle that computer vision models will have to solve as well.</p>
</div>
</div>
<div id="illusions" class="section level3 unnumbered hasAnchor">
<h3>Illusions<a href="perception.html#illusions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:constancy"></span>
<img src="images/ch2/fig4.jpg" alt="Optical Illusions as a Result of Brightness Constancy (Left) and Color Constancy (Right). Look carefully at the snakelike pattern on the left. Are the green strips really brighter than the background? Cover the white curves and you’ll see they are not. Square A in the right-hand image looks very different from square B, even though they are exactly the same." width="60%" />
<p class="caption">
Figure 2.5: Optical Illusions as a Result of Brightness Constancy (Left) and Color Constancy (Right). Look carefully at the snakelike pattern on the left. Are the green strips really brighter than the background? Cover the white curves and you’ll see they are not. Square A in the right-hand image looks very different from square B, even though they are exactly the same.
</p>
</div>
<p>Although our perception is very accurate, it is not perfect. <a href="perception.html#illusions">Illusions</a> occur when the perceptual processes that normally help us correctly perceive the world around us are fooled by a particular situation so that we see something that does not exist or that is incorrect. Figure <a href="perception.html#fig:constancy">2.5</a> presents two situations in which our normally accurate perceptions of visual constancy have been fooled.</p>
<p>Another well-known illusion is the <a href="perception.html#mueller-lyer-illusion">Mueller-Lyer illusion</a> (see Figure <a href="perception.html#fig:muellerlyer">2.6</a>). The line segment in the bottom arrow looks longer to us than the one on the top, even though they are both actually the same length. It is likely that the illusion is, in part, the result of the failure of monocular depth cues — the bottom line looks like an edge that is normally farther away from us, whereas the top one looks like an edge that is normally closer.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:muellerlyer"></span>
<img src="images/ch2/fig5.jpg" alt="The Mueller-Lyer illusion makes the line segment at the top of the left picture appear shorter than the one at the bottom. The illusion is caused, in part, by the monocular distance cue of depth — the bottom line looks like an edge that is normally farther away from us, whereas the top one looks like an edge that is normally closer." width="60%" />
<p class="caption">
Figure 2.6: The Mueller-Lyer illusion makes the line segment at the top of the left picture appear shorter than the one at the bottom. The illusion is caused, in part, by the monocular distance cue of depth — the bottom line looks like an edge that is normally farther away from us, whereas the top one looks like an edge that is normally closer.
</p>
</div>
<p>The Ponzo illusion operates on the same principle. As you can see in Figure <a href="perception.html#fig:ponzoillusion">2.7</a>, the top yellow bar seems longer than the bottom one, but if you measure them you’ll see that they are exactly the same length. The monocular depth cue of linear perspective leads us to believe that, given two similar objects, the distant one can only cast the same size retinal image as the closer object if it is larger. The topmost bar therefore appears longer.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ponzoillusion"></span>
<img src="images/ch2/fig7.jpg" alt="The Ponzo Illusion. The Ponzo illusion is caused by a failure of the monocular depth cue of linear perspective. Both bars are the same size, even though the top one looks larger." width="60%" />
<p class="caption">
Figure 2.7: The Ponzo Illusion. The Ponzo illusion is caused by a failure of the monocular depth cue of linear perspective. Both bars are the same size, even though the top one looks larger.
</p>
</div>
<p>Illusions demonstrate that our perception of the world around us may be influenced by our prior knowledge. But the fact that some illusions exist in some cases does not mean that the perceptual system is generally inaccurate — in fact, humans normally become so closely in touch with their environment that the physical body and the particular environment that we sense and perceive becomes <a href="perception.html#embodied">embodied</a> — that is, built into and linked with our cognition, such that the world around us becomes part of our brain <span class="citation">(<a href="#ref-calvo2008handbook">Calvo &amp; Gomila, 2008</a>)</span>. The close relationship between people and their environments means that, although illusions can be created in the lab and under some unique situations, they may be less common with active observers in the real world <span class="citation">(<a href="#ref-Runeson1988">Runeson, 1988</a>)</span>.</p>
</div>
<div id="the-important-role-of-expectations-in-perception" class="section level3 unnumbered hasAnchor">
<h3>The Important Role of Expectations in Perception<a href="perception.html#the-important-role-of-expectations-in-perception" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our emotions, mindset, expectations, and the contexts in which our sensations occur all have a profound influence on perception. People who are warned that they are about to taste something bad rate what they do taste more negatively than people who are told that the taste won’t be so bad <span class="citation">(<a href="#ref-nitschke2006altering">Nitschke et al., 2006</a>)</span>, and people perceive a child and adult pair as looking more alike when they are told that they are parent and child <span class="citation">(<a href="#ref-Bressan2002">Bressan &amp; Dal Martello, 2002</a>)</span>. Similarly, participants who see images of the same baby rate it as stronger and bigger when they are told it is a boy as opposed to when they are told it is a girl <span class="citation">(<a href="#ref-Stern1989">Stern &amp; Karraker, 1989</a>)</span>, and research participants who learn that a child is from a lower-class background perceive the child’s scores on an intelligence test as lower than people who see the same test taken by a child they are told is from an upper-class background <span class="citation">(<a href="#ref-Darley1983">Darley &amp; Gross, 1983a</a>)</span>. <span class="citation">Plassmann et al. (<a href="#ref-plassmann2008marketing">2008</a>)</span> found that wines were rated more positively and caused greater brain activity in brain areas associated with pleasure when they were said to cost more than when they were said to cost less. And even experts can be fooled: professional referees tended to assign more penalty cards to soccer teams for videotaped fouls when they were told that the team had a history of aggressive behavior than when they had no such expectation <span class="citation">(<a href="#ref-Jones2002">Jones et al., 2002</a>)</span>.</p>
<div id="psychology-in-everyday-life-how-understanding-sensation-and-perception-can-save-lives" class="section level5 unnumbered hasAnchor fyi">
<h5>Psychology in Everyday Life: How Understanding Sensation and Perception Can Save Lives<a href="perception.html#psychology-in-everyday-life-how-understanding-sensation-and-perception-can-save-lives" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><a href="perception.html#human-factors">Human factors</a> is the field of psychology that uses psychological knowledge, including the principles of sensation and perception, to improve the development of technology. Human factors has worked on a variety of projects, ranging from nuclear reactor control centers and airplane cockpits to cell phones and websites <span class="citation">(<a href="#ref-Proctor2008">Proctor &amp; Van Zandt, 2008</a>)</span>. For instance, knowledge of the visual system also helped engineers create new kinds of displays, such as those used on notebook computers and music players, and better understand how using cell phones while driving may contribute to automobile accidents <span class="citation">(<a href="#ref-Lee2004">Lee &amp; Strayer, 2004</a>)</span>. Human factors also has made substantial contributions to airline safety. About two-thirds of accidents on commercial airplane flights are caused by human error <span class="citation">(<a href="#ref-Nickerson1998">Nickerson, 1998a</a>)</span>. During takeoff, travel, and landing, the pilot simultaneously communicates with ground control, maneuvers the plane, scans the horizon for other aircraft, and operates controls. The need for a usable interface that works easily and naturally with the pilot’s visual perception is essential.</p>
<p>Psychologist <span class="citation">Kraft (<a href="#ref-Kraft1978">1978</a>)</span> hypothesized that as planes land, with no other distance cues visible, pilots may be subjected to a type of moon illusion, in which the city lights beyond the runway appear much larger on the retina than they really are, deceiving the pilot into landing too early. Kraft’s findings caused airlines to institute new flight safety measures, where copilots must call out the altitude progressively during the descent, which has probably decreased the number of landing accidents.</p>
<p>Figure <a href="perception.html#fig:humanfactors">2.8</a> presents images of an airplane instrument panel before and after it was redesigned by human factors psychologists. On the left is the initial design, in which the controls were crowded and cluttered, in no logical sequence, each control performing one task. The controls were more or less the same in color, and the gauges were not easy to read. The redesigned digital cockpit shows a marked improvement in usability. More of the controls are color-coded and multifunctional so that there is less clutter on the dashboard. Screens make use of LCD and 3-D graphics. Text sizes are changeable — increasing readability — and many of the functions have become automated, freeing up the pilots’ concentration for more important activities.</p>
<p>One important aspect of the redesign was based on the principles of sensory adaptation. Displays that are easy to see in darker conditions quickly become unreadable when the sun shines directly on them. It takes the pilot a relatively long time to adapt to the suddenly much brighter display. Furthermore, perceptual contrast is important. The display cannot be so bright at night that the pilot is unable to see targets in the sky or on the land. Human factors psychologists used these principles to determine the appropriate stimulus intensity needed on these displays so that pilots would be able to read them accurately and quickly under a wide range of conditions. The psychologists accomplished this by developing an automatic control mechanism that senses the ambient light visible through the front cockpit windows and detects the light falling on the display surface, and then automatically adjusts the intensity of the display for the pilot <span class="citation">(<a href="#ref-Silverstein1990">Silverstein et al., 1990</a>; <a href="#ref-Silverstein1985">Silverstein &amp; Merrifield, 1985</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:humanfactors"></span>
<img src="images/ch2/fig8.jpg" alt="Airplane instrument panel before and after it was redesigned by human factors psychologists." width="90%" />
<p class="caption">
Figure 2.8: Airplane instrument panel before and after it was redesigned by human factors psychologists.
</p>
</div>
</div>
<div id="key-takeaways-1" class="section level5 unnumbered hasAnchor takeaways">
<h5>Key Takeaways<a href="perception.html#key-takeaways-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Sensation is the process of receiving information from the environment through our sensory organs. Perception is the process of interpreting and organizing the incoming information so that we can understand it and react accordingly.</li>
<li>The retina has two types of photoreceptor cells: rods, which detect brightness and respond to black and white, and cones, which respond to red, green, and blue. Colour blindness occurs when people lack function in the red- or green-sensitive cones.
Feature detector neurons in the visual cortex help us recognize objects, and some neurons respond selectively to faces and other body parts.</li>
<li>The ability to perceive depth occurs as the result of binocular and monocular depth cues.</li>
<li>Perceptual constancy allows us to perceive an object as the same, despite changes in sensation.</li>
<li>Cognitive illusions are examples of how our expectations can influence our perceptions.</li>
</ul>
</div>
<div id="exercises-1" class="section level5 unnumbered hasAnchor exercises">
<h5>Exercises<a href="perception.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li>Practice: List some ways that the processes of visual perception help you engage in an everyday activity, such as driving a car or riding a bicycle.</li>
<li>Discussion: What are some cases where your expectations about what you thought you were going to experience influenced your perceptions of what you actually experienced?</li>
</ol>
</div>
</div>
</div>
<div id="glossary-1" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Glossary<a href="perception.html#glossary-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="binocular-depth-cues" class="section level5 unnumbered hasAnchor">
<h5>binocular depth cues<a href="perception.html#binocular-depth-cues" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Depth cues that are created by retinal image disparity — that is, the space between our eyes — and which thus require the coordination of both eyes</p>
</div>
<div id="blind-spot" class="section level5 unnumbered hasAnchor">
<h5>blind spot<a href="perception.html#blind-spot" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A hole in our vision where the optic nerve leaves the retina</p>
</div>
<div id="computer-vision" class="section level5 unnumbered hasAnchor">
<h5>computer vision<a href="perception.html#computer-vision" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Machines or algorithms that are built to mimic the human sensation and perception system</p>
</div>
<div id="cones" class="section level5 unnumbered hasAnchor">
<h5>cones<a href="perception.html#cones" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Visual neurons that are specialized in detecting fine detail and colours</p>
</div>
<div id="convergence" class="section level5 unnumbered hasAnchor">
<h5>convergence<a href="perception.html#convergence" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>the inward turning of our eyes that is required to focus on objects that are less than about 50 feet away from us</p>
</div>
<div id="cornea" class="section level5 unnumbered hasAnchor">
<h5>cornea<a href="perception.html#cornea" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A clear covering that protects the eye and begins to focus the incoming light</p>
</div>
<div id="depth-cues" class="section level5 unnumbered hasAnchor">
<h5>depth cues<a href="perception.html#depth-cues" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Messages from our bodies and the external environment that supply us with information about space and distance</p>
</div>
<div id="depth-perception" class="section level5 unnumbered hasAnchor">
<h5>depth perception<a href="perception.html#depth-perception" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The ability to perceive three-dimensional space and to accurately judge distance</p>
</div>
<div id="embodied" class="section level5 unnumbered hasAnchor">
<h5>embodied<a href="perception.html#embodied" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The particular environment that we sense and perceive becomes built into and linked with our cognition</p>
</div>
<div id="fovea" class="section level5 unnumbered hasAnchor">
<h5>fovea<a href="perception.html#fovea" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The central point of the retina</p>
</div>
<div id="gestalt" class="section level5 unnumbered hasAnchor">
<h5>gestalt<a href="perception.html#gestalt" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A meaningfully organized whole</p>
</div>
<div id="human-factors" class="section level5 unnumbered hasAnchor">
<h5>human factors<a href="perception.html#human-factors" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The field of psychology that uses psychological knowledge, including the principles of sensation and perception, to improve the development of technology</p>
</div>
<div id="iris" class="section level5 unnumbered hasAnchor">
<h5>iris<a href="perception.html#iris" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The coloured part of the eye that controls the size of the pupil by constricting or dilating in response to light intensity</p>
</div>
<div id="lens" class="section level5 unnumbered hasAnchor">
<h5>lens<a href="perception.html#lens" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A structure that focuses the incoming light on the retina</p>
</div>
<div id="mcgurk-effect" class="section level5 unnumbered hasAnchor">
<h5>McGurk Effect<a href="perception.html#mcgurk-effect" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>An error in perception that occurs when we misperceive sounds because the audio and visual parts of the speech are mismatched</p>
</div>
<div id="monocular-depth-cues" class="section level5 unnumbered hasAnchor">
<h5>monocular depth cues<a href="perception.html#monocular-depth-cues" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Depth cues that help us perceive depth using only one eye</p>
</div>
<div id="mueller-lyer-illusion" class="section level5 unnumbered hasAnchor">
<h5>Mueller-Lyer Illusion<a href="perception.html#mueller-lyer-illusion" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>An illusion in which one line segment looks longer than another based on converging or diverging angles at the ends of the lines.</p>
</div>
<div id="optic-nerve" class="section level5 unnumbered hasAnchor">
<h5>optic nerve<a href="perception.html#optic-nerve" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A collection of millions of ganglion neurons that sends vast amounts of visual information to the brain</p>
</div>
<div id="perception-1" class="section level5 unnumbered hasAnchor">
<h5>perception<a href="perception.html#perception-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The process of interpreting and organizing the incoming information so that we can understand it and react accordingly</p>
</div>
<div id="perceptual-constancy" class="section level5 unnumbered hasAnchor">
<h5>perceptual constancy<a href="perception.html#perceptual-constancy" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The ability to perceive a stimulus as constant despite changes in sensation</p>
</div>
<div id="pupil" class="section level5 unnumbered hasAnchor">
<h5>pupil<a href="perception.html#pupil" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A small opening in the centre of the eye</p>
</div>
<div id="retina" class="section level5 unnumbered hasAnchor">
<h5>retina<a href="perception.html#retina" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The layer of tissue at the back of the eye that contains photoreceptor cells</p>
</div>
<div id="rods" class="section level5 unnumbered hasAnchor">
<h5>rods<a href="perception.html#rods" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Visual neurons that specialize in detecting black, white, and gray colours</p>
</div>
<div id="saccades" class="section level5 unnumbered hasAnchor">
<h5>saccades<a href="perception.html#saccades" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The rapid shifting of the eyes from one fixation point to another</p>
</div>
<div id="sensation" class="section level5 unnumbered hasAnchor">
<h5>sensation<a href="perception.html#sensation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The process of receiving information from the environment through our sensory organs</p>
</div>
<div id="sensory-adaptation" class="section level5 unnumbered hasAnchor">
<h5>sensory adaptation<a href="perception.html#sensory-adaptation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A decreased sensitivity to a stimulus after prolonged and constant exposure</p>
</div>
<div id="sensory-interaction" class="section level5 unnumbered hasAnchor">
<h5>sensory interaction<a href="perception.html#sensory-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The working together of different senses to create experience</p>
</div>
<div id="synesthesia" class="section level5 unnumbered hasAnchor">
<h5>synesthesia<a href="perception.html#synesthesia" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>An experience in which one sensation (e.g., seeing a number) creates experiences in another (e.g., hearing a sound)</p>
</div>
<div id="transduction" class="section level5 unnumbered hasAnchor">
<h5>transduction<a href="perception.html#transduction" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The conversion of light detected by receptor cells to electrical impulses that are transported to the brain</p>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-Bressan2002" class="csl-entry">
Bressan, P., &amp; Dal Martello, M. F. (2002). Talis pater, talis filius: Perceived resemblance and the belief in genetic relatedness. <em>Psychological Science</em>, <em>13</em>, 213–218.
</div>
<div id="ref-calvo2008handbook" class="csl-entry">
Calvo, P., &amp; Gomila, T. (2008). <em>Handbook of cognitive science: An embodied approach</em>. Elsevier.
</div>
<div id="ref-Darley1983" class="csl-entry">
Darley, J. M., &amp; Gross, P. H. (1983a). A hypothesis-confirming bias in labeling effects. <em>Journal of Personality and Social Psychology</em>, <em>44</em>, 20–33.
</div>
<div id="ref-Enns2008" class="csl-entry">
Enns, J. T., &amp; Lleras, A. (2008). What’s next? New evidence for prediction in human vision. <em>Trends in Cognitive Sciences</em>, <em>12</em>(9), 327–333.
</div>
<div id="ref-Flanagan2004" class="csl-entry">
Flanagan, M. B., May, J. G., &amp; Dobie, T. G. (2004). The role of vection, eye movements, and postural instability in the etiology of motion sickness. <em>Journal of Vestibular Research: Equilibrium and Orientation</em>, <em>14</em>(4), 335–346.
</div>
<div id="ref-Galanter1962" class="csl-entry">
Galanter, E. (1962). <em>Contemporary psychophysics. In r. Brown, e. Galanter, e. H. Hess, &amp; g. Mandler (eds.), new directions in psychology</em>. Holt, Rinehart; Winston.
</div>
<div id="ref-Gibson2000" class="csl-entry">
Gibson, E. J., Pick, A. D., et al. (2000). <em>An ecological approach to perceptual learning and development</em>. Oxford University Press, USA.
</div>
<div id="ref-Goodale2006" class="csl-entry">
Goodale, M., &amp; Milner, D. (2006). One brain-two visual systems. <em>Psychologist</em>, <em>19</em>(11), 660–663.
</div>
<div id="ref-Howard2001" class="csl-entry">
Howard, I. P. (2002). <em>Seeing in depth, vol. 1: Basic mechanisms.</em> University of Toronto Press.
</div>
<div id="ref-Jones2002" class="csl-entry">
Jones, M. V., Paull, G. C., &amp; Erskine, J. (2002). The impact of a team’s aggressive reputation on the decisions of association football referees. <em>Journal of Sports Sciences</em>, <em>20</em>, 991–1000.
</div>
<div id="ref-Kraft1978" class="csl-entry">
Kraft, C. (1978). <em>A psychophysical approach to air safety: Simulator studies of visual illusions in night approaches. In h. L. Pick, h. W. Leibowitz, j. E. Singer, a. Steinschneider, &amp; h. W. Steenson (eds.), psychology: From research to practice</em> (2nd ed.). Plenum Press.
</div>
<div id="ref-Lee2004" class="csl-entry">
Lee, J., &amp; Strayer, D. (2004). Preface to the special section on driver distraction. <em>Human Factors</em>, <em>46</em>(4), 583.
</div>
<div id="ref-livingstone2000warm" class="csl-entry">
Livingstone, M. S. (2000). Is it warm? Is it real? Or just low spatial frequency? <em>Science</em>, <em>290</em>(5495), 1299–1299.
</div>
<div id="ref-McCann1992" class="csl-entry">
McCann, J. J. (1992). Rules for color constancy. <em>Ophthalmic and Physiologic Optics</em>, <em>12</em>(2), 175–177.
</div>
<div id="ref-Nickerson1998" class="csl-entry">
Nickerson, R. S. (1998a). Applied psychology: An international review. <em>Applied Experimental Psychology</em>, <em>47</em>, 155–173.
</div>
<div id="ref-nitschke2006altering" class="csl-entry">
Nitschke, J. B., Dixon, G. E., Sarinopoulos, I., Short, S. J., Cohen, J. D., Smith, E. E., Kosslyn, S. M., Rose, R. M., &amp; Davidson, R. J. (2006). Altering expectancy dampens neural response to aversive taste in primary taste cortex. <em>Nature Neuroscience</em>, <em>9</em>(3), 435–442.
</div>
<div id="ref-plassmann2008marketing" class="csl-entry">
Plassmann, H., O’doherty, J., Shiv, B., &amp; Rangel, A. (2008). Marketing actions can modulate neural representations of experienced pleasantness. <em>Proceedings of the National Academy of Sciences</em>, <em>105</em>(3), 1050–1054.
</div>
<div id="ref-Proctor2008" class="csl-entry">
Proctor, R. W., &amp; Van Zandt, T. (2008). <em>Human factors in simple and complex systems.</em> (2nd ed.). CRC Press.
</div>
<div id="ref-Ramachandran2005" class="csl-entry">
Ramachandran, V. S., Hubbard, E. M., Robertson, L. C., &amp; Sagiv, N. (2005). <em>The emergence of the human mind: Some clues from synesthesia. In synesthesia: Perspectives from cognitive neuroscience.</em> (2nd ed., pp. 147–190). Oxford University Press.
</div>
<div id="ref-Runeson1988" class="csl-entry">
Runeson, S. (1988). The distorted room illusion, equivalent configurations, and the specificity of static optic arrays. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>14</em>(2), 295–304.
</div>
<div id="ref-Sekuler2006" class="csl-entry">
Sekuler, R., &amp; Blake, R. (2006). <em>Perception</em>. McGraw-Hill Companies,Incorporated. <a href="https://books.google.com/books?id=jKVFAAAAYAAJ">https://books.google.com/books?id=jKVFAAAAYAAJ</a>
</div>
<div id="ref-Silverstein1990" class="csl-entry">
Silverstein, L. D., Krantz, J. H., Gomer, F. E., Yeh, Y., &amp; Monty, R. W. (1990). The effects of spatial sampling and luminance quantization on the image quality of color matrix displays. <em>Journal of the Optical Society of America</em>, <em>Part A</em>(7), 1955–1968.
</div>
<div id="ref-Silverstein1985" class="csl-entry">
Silverstein, L. D., &amp; Merrifield, R. M. (1985). <em>The development and evaluation of color systems for airborne applications: Phase i fundamental visual, perceptual, and display systems considerations (tech. Report DOT/FAA/PM085019)</em> (5th ed., pp. 1955–1968). Federal Aviation Administration.
</div>
<div id="ref-Stern1989" class="csl-entry">
Stern, M., &amp; Karraker, K. H. (1989). Sex stereotyping of infants: A review of gender labeling studies. <em>Sex Roles</em>, <em>20</em>(9–10), 501–522.
</div>
<div id="ref-Stoffregen2001" class="csl-entry">
Stoffregen, T. A., &amp; Bardy, B. G. (2001). On specification and the senses. <em>Behavioral and Brain Sciences</em>, <em>24</em>(2), 195–213.
</div>
<div id="ref-Williams2022" class="csl-entry">
Williams, J. R., Markov, Y. A., Tiurina, N. A., &amp; Störmer, V. S. (2022). What you see is what you hear: Sounds alter the contents of visual perception. <em>Psychological Science</em>, 09567976221121348.
</div>
<div id="ref-Yarbus1967" class="csl-entry">
Yarbus, A. L. (1967). <em>Eye movements and vision</em>. Plenum Press.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="history-and-research-methods.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="attention.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": false,
    "twitter": false,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": false
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/pilegard/cogfoundations/edit/main/02-perception.Rmd",
    "text": "Suggest an edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["cogfoundations.pdf", "https://github.com/pilegard/cogfoundations/raw/main/02-perception.Rmd"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
